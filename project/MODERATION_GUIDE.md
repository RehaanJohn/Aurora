# AI Moderation System - Visual Guide

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    User Types Message                        â”‚
â”‚                  "This is f*cking awesome!"                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              STEP 1: Basic Profanity Filter                  â”‚
â”‚                   (filter.ts - Instant)                      â”‚
â”‚                                                              â”‚
â”‚  â€¢ Scans for known profanity words                          â”‚
â”‚  â€¢ Creates cleaned version: "This is ******* awesome!"      â”‚
â”‚  â€¢ Returns: blocked=true, detected=["fucking"]              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚                    â”‚
         NO PROFANITY         PROFANITY FOUND
              â”‚                    â”‚
              â–¼                    â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ Allow & Send â”‚   â”‚  STEP 2: AI Analysis     â”‚
      â”‚   Directly   â”‚   â”‚  (aiAgent.ts - ~1 sec)   â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚                          â”‚
                         â”‚  Google Gemini 1.5 Flash â”‚
                         â”‚  analyzes context:       â”‚
                         â”‚                          â”‚
                         â”‚  â€¢ Intent (hostile?)     â”‚
                         â”‚  â€¢ Context (humor?)      â”‚
                         â”‚  â€¢ Target (person?)      â”‚
                         â”‚  â€¢ Tone (angry?)         â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                           â”‚
              HARMFUL INTENT              NOT HARMFUL
                    â”‚                           â”‚
                    â–¼                           â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  BLOCK MESSAGE   â”‚        â”‚  ALLOW MESSAGE   â”‚
          â”‚                  â”‚        â”‚                  â”‚
          â”‚  Show warning:   â”‚        â”‚  Send original   â”‚
          â”‚  "âš ï¸ Blocked:    â”‚        â”‚  or cleaned msg  â”‚
          â”‚   Harassment"    â”‚        â”‚                  â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ Example Scenarios

### Scenario 1: Clean Message âœ…

```
Input: "Hello, how are you today?"
       â†“
Profanity Filter: âœ… Clean
       â†“
Result: ALLOW (no AI needed)
```

### Scenario 2: Casual Profanity âœ…

```
Input: "This game is fucking amazing!"
       â†“
Profanity Filter: âš ï¸ Found "fucking"
       â†“
AI Analysis:
  - Intent: Enthusiastic
  - Context: Positive statement about game
  - Tone: Excited, not hostile
  - Target: None (talking about game)
       â†“
Decision: NOT HARMFUL
       â†“
Result: ALLOW with message "Profanity detected but not harmful intent"
```

### Scenario 3: Harassment âŒ

```
Input: "You're fucking useless"
       â†“
Profanity Filter: âš ï¸ Found "fucking"
       â†“
AI Analysis:
  - Intent: Insulting
  - Context: Personal attack
  - Tone: Hostile
  - Target: Direct person attack
       â†“
Decision: HARMFUL
       â†“
Result: BLOCK
Reason: "Direct personal insult with hostile intent"
Categories: ["Harassment", "Toxic"]
```

### Scenario 4: Threat âŒ

```
Input: "I'm going to kill you"
       â†“
Profanity Filter: âœ… Clean (no profanity)
       â†“
AI Analysis: (runs anyway for threats)
  - Intent: Threatening
  - Context: Violence implied
  - Tone: Dangerous
  - Target: Person
       â†“
Decision: HARMFUL
       â†“
Result: BLOCK
Categories: ["Dangerous", "Harassment"]
```

## ğŸ”„ Message Flow in Chat Component

```typescript
// 1. User clicks Send
handleSendMessage() {

  // 2. Run moderation
  const result = await moderateMessage(messageInput)

  // 3. Check decision
  if (!result.allowed) {
    // Show warning banner
    setModerationWarning("âš ï¸ Message blocked: ...")
    return
  }

  // 4. Message approved - add to chat
  setMessages([...messages, newMessage])

  // 5. Clear input
  setMessageInput("")
}
```

## ğŸ“Š Decision Matrix

| Message Type        | Profanity? | AI Decision | Result   |
| ------------------- | ---------- | ----------- | -------- |
| "Hello friend"      | âŒ         | N/A         | âœ… Allow |
| "F\*ck yeah!"       | âœ…         | Not harmful | âœ… Allow |
| "You're an idiot"   | âŒ         | Harmful     | âŒ Block |
| "I hate you"        | âŒ         | Harmful     | âŒ Block |
| "This sh\*t works!" | âœ…         | Not harmful | âœ… Allow |
| "Kill yourself"     | âŒ         | Dangerous   | âŒ Block |

## ğŸ¨ UI States

### 1. Normal State

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Message #general                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[Send]
```

### 2. Checking State (AI analyzing)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Message #general                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[Send] Checking...
```

### 3. Blocked State

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âš ï¸ Message blocked: Harassment, Toxic       â”‚
â”‚ Direct personal insult with hostile intent  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Message #general                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[Send]
```

### 4. Info State (profanity cleaned)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â„¹ï¸ Profanity detected but not harmful       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Message #general                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[Send]
```

## âš™ï¸ Configuration Files

### .env

```env
VITE_GEMINI_API_KEY=your_key_here
```

### aiAgent.ts

- Google Gemini integration
- Context analysis logic
- JSON response parsing

### filter.ts

- Profanity word list
- Basic pattern matching
- Message cleaning

### index.ts

- Combines both systems
- Decision logic
- Error handling

## ğŸ” Privacy & Security

- âœ… Messages analyzed in real-time (not stored)
- âœ… AI runs on Google's secure servers
- âœ… No message history kept by moderation system
- âœ… Each message analyzed independently
- âœ… User sees reason for blocked messages

## ğŸ“ˆ Performance

| Operation           | Time | Notes                     |
| ------------------- | ---- | ------------------------- |
| Profanity Filter    | <1ms | Instant regex check       |
| AI Analysis         | ~1s  | Only when profanity found |
| Total (clean msg)   | <1ms | No AI needed              |
| Total (profane msg) | ~1s  | Includes AI analysis      |

## ğŸ¯ Success Metrics

The system should:

- âœ… Block 100% of direct harassment
- âœ… Block 100% of threats
- âœ… Allow 90%+ of casual profanity in positive context
- âœ… Provide clear explanations for blocks
- âœ… Have <2s latency for AI decisions
